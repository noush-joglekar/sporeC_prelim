{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/2023_03_01_v0_dataGathering/PoreC_Fibroblasts/'\n",
    "chromSizes = pd.read_csv(f'{dataDir}hg38.chromSizes',sep=\"\\t\", names = ['chr','size']).set_index('chr')['size'].to_dict()\n",
    "readConcatemersWClosestGene = f'{dataDir}neonatal_fragsOutput_byChr/neonatal_fibroblasts_chr2.gz'\n",
    "colnames = [\"chr\",\"start\",\"end\",\"readID\",\"readLen\",\"readQual\",\n",
    "\"geneChr\",\"geneStart\",\"geneEnd\",\"strand\",\"geneID\",\"bioType\",\"geneName\",\"dist\",\"ID\"]\n",
    "\n",
    "fullBed = pd.read_csv(readConcatemersWClosestGene,sep = \"\\t\",names = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr19 = fullBed[fullBed['chr']==\"chr2\"]\n",
    "binSize = 1*10**6 #5*10**5\n",
    "chrBins = [x for x in range(0,chromSizes['chr2']+binSize,binSize)]\n",
    "chr19_binned = pd.cut(chr19['start'],bins = chrBins, labels = [\"Bin\"+str(i+1) for i in range(len(chrBins)-1)]).rename(\"binID\")\n",
    "chr19_wBinID = chr19.merge(chr19_binned,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>binID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612155</th>\n",
       "      <td>382207</td>\n",
       "      <td>Bin242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612156</th>\n",
       "      <td>382208</td>\n",
       "      <td>Bin242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612157</th>\n",
       "      <td>382045</td>\n",
       "      <td>Bin243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612158</th>\n",
       "      <td>382209</td>\n",
       "      <td>Bin243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612159</th>\n",
       "      <td>382210</td>\n",
       "      <td>Bin243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID   binID\n",
       "612155  382207  Bin242\n",
       "612156  382208  Bin242\n",
       "612157  382045  Bin243\n",
       "612158  382209  Bin243\n",
       "612159  382210  Bin243"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr19_wBinID[['ID','binID']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedBins = chr19_wBinID.groupby('ID')['binID'].apply(list).reset_index(name='Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105355\n",
      "105355\n"
     ]
    }
   ],
   "source": [
    "def sort_key(item):\n",
    "    return int(item.split('Bin')[1])\n",
    "\n",
    "edges = [\"_\".join(sorted(list(set(a)), key=sort_key)) for a in groupedBins['Bins'] if len(list(set(a))) > 1]\n",
    "readIDs = [groupedBins.iloc[ix][0] for ix in range(len(groupedBins)) if len(list(set(groupedBins.iloc[ix][1]))) > 1]\n",
    "print(len(edges))\n",
    "print(len(readIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "edgeDict = dict(Counter(edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57618"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edgeDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'{dataDir}adult_chr2_dict.pkl','wb') as f:\n",
    "    pickle.dump(edgeDict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/v0.analysis/scripts/pythonScripts/functions/')\n",
    "from promethData_multiwayExpectedProbs import multiwayEval_realData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/2023_03_01_v0_dataGathering/PoreC_Fibroblasts/'\n",
    "runDir = 'v1.evaluateExpectedVersusInteresting_adult/'\n",
    "plotDir = f'{dataDir}{runDir}Plots_adult_chr2/'\n",
    "outDir = f'{dataDir}{runDir}dfs_adult_chr2/'\n",
    "inputPkl = 'adult_chr2_dict.pkl'\n",
    "probHashOutName = f'{outDir}probHash_chr2.json'\n",
    "\n",
    "seed = 1\n",
    "quartile = 25\n",
    "toChoose = 400\n",
    "toPlotRef = False\n",
    "toPlotInd = False\n",
    "toPlotScatter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in hyperedge pickle file\n",
      "Processing all the hyperedges from pickle file\n",
      "A total of 57618 initial interactions\n",
      "Updated the input: retaining 16581 interactions with chain support of at least 2\n",
      "Expected probabilities file does not exist...creating now\n",
      "Calculating for card= 8\n",
      "There are  2 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "Creating a probability hash for 3-way subsets\n",
      "Creating a probability hash for 4-way subsets\n",
      "Creating a probability hash for 5-way subsets\n",
      "Creating a probability hash for 6-way subsets\n",
      "Creating a probability hash for 7-way subsets\n",
      "Calculating for card= 7\n",
      "There are  1 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "Creating a probability hash for 3-way subsets\n",
      "Creating a probability hash for 4-way subsets\n",
      "Creating a probability hash for 5-way subsets\n",
      "Creating a probability hash for 6-way subsets\n",
      "Calculating for card= 6\n",
      "There are  4 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "Creating a probability hash for 3-way subsets\n",
      "Creating a probability hash for 4-way subsets\n",
      "Creating a probability hash for 5-way subsets\n",
      "Calculating for card= 5\n",
      "There are  12 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "Creating a probability hash for 3-way subsets\n",
      "Creating a probability hash for 4-way subsets\n",
      "Calculating for card= 4\n",
      "There are  45 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "Creating a probability hash for 3-way subsets\n",
      "Calculating for card= 3\n",
      "There are  938 reads\n",
      "Creating a probability hash for 2-way subsets\n",
      "File created...moving on\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "print(\"Loading in hyperedge pickle file\")\n",
    "with open(f'{dataDir}/{inputPkl}','rb') as f:\n",
    "    hpEdges = pickle.load(f)\n",
    "\n",
    "print(\"Processing all the hyperedges from pickle file\")\n",
    "hpKeys = [k for k in hpEdges.keys()]\n",
    "print(\"A total of\",len(hpKeys),\"initial interactions\")\n",
    "\n",
    "readSupport = [v for v in hpEdges.values()]\n",
    "atLeastTwoChains = [i for i,x in enumerate(readSupport) if x >=2]\n",
    "updatedDict = {hpKeys[i]:readSupport[i] for i in atLeastTwoChains}\n",
    "\n",
    "hpKeys = [k for k in updatedDict.keys()]\n",
    "hpKeys_split = [k.split(\"_\") for k in updatedDict.keys()]\n",
    "keyCard = [len(item) for item in hpKeys_split]\n",
    "\n",
    "print(\"Updated the input: retaining\",len(hpKeys),\n",
    "        \"interactions with chain support of at least 2\")\n",
    "\n",
    "evalInstance = multiwayEval_realData(keyCard, updatedDict, hpKeys, hpKeys_split, seed,\n",
    "                            toChoose, toPlotRef, toPlotInd, toPlotScatter,\n",
    "                            quartile, plotDir,outDir)\n",
    "\n",
    "if os.path.exists(probHashOutName):\n",
    "    print(\"Expected probabilities file already exists...moving on\")\n",
    "    with open(probHashOutName,'r') as file:\n",
    "        tmpHash = json.load(file)\n",
    "        # probHash = {key: {int(k): v for k, v in value.items() if value is not None} \n",
    "        #             if value is not None else None for key, value in tmpHash.items()}\n",
    "        probHash = {key: {int(k): v for k, v in value.items()} for key, value in tmpHash.items() if value is not None}\n",
    "\n",
    "else:\n",
    "    print(\"Expected probabilities file does not exist...creating now\")\n",
    "    probHash = evalInstance.makeAllReferenceHashDicts()\n",
    "    with open(probHashOutName,'w') as file:\n",
    "        json.dump(probHash,file)\n",
    "    print(\"File created...moving on\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalInstance = multiwayEval_realData(keyCard, updatedDict, hpKeys, hpKeys_split, seed,\n",
    "                            toChoose, toPlotRef, toPlotInd, toPlotScatter,\n",
    "                            quartile, plotDir,outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# dict(Counter(keyCard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import promethData_multiwayExpectedProbs\n",
    "importlib.reload(promethData_multiwayExpectedProbs)\n",
    "\n",
    "from promethData_multiwayExpectedProbs import multiwayEval_realData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating for card= 8\n",
      "There are  2 reads\n",
      "Calculating stats for 2 reads\n",
      "Writing output for wDist\n",
      "Writing output for cosineSim\n",
      "Writing output for eDist\n",
      "Writing output for empDist\n",
      "Calculating for card= 7\n",
      "There are  1 reads\n",
      "Calculating for card= 6\n",
      "There are  4 reads\n",
      "Calculating stats for 4 reads\n",
      "Writing output for wDist\n",
      "Writing output for cosineSim\n",
      "Writing output for eDist\n",
      "Writing output for empDist\n",
      "Calculating for card= 5\n",
      "There are  12 reads\n",
      "Calculating stats for 12 reads\n",
      "Writing output for wDist\n",
      "Writing output for cosineSim\n",
      "Writing output for eDist\n",
      "Writing output for empDist\n",
      "Calculating for card= 4\n",
      "There are  45 reads\n",
      "Calculating stats for 45 reads\n",
      "Writing output for wDist\n",
      "Writing output for cosineSim\n",
      "Writing output for eDist\n",
      "Writing output for empDist\n",
      "Calculating for card= 3\n",
      "There are  938 reads\n",
      "Calculating stats for 938 reads\n",
      "Writing output for wDist\n",
      "Writing output for cosineSim\n",
      "Writing output for eDist\n",
      "Writing output for empDist\n"
     ]
    }
   ],
   "source": [
    "toChoose = 1000\n",
    "\n",
    "evalInstance = multiwayEval_realData(keyCard, updatedDict, hpKeys, hpKeys_split, seed,\n",
    "                            toChoose, toPlotRef, toPlotInd, toPlotScatter,\n",
    "                            quartile, plotDir,outDir)\n",
    "\n",
    "A = evalInstance.statsForAllReads(probHash)\n",
    "\n",
    "# card = 6\n",
    "# ixList = [index for index,element in enumerate(keyCard) if element == card]\n",
    "# print(len(ixList))\n",
    "\n",
    "# evalInstance.getReadExpectednessStats(6,ixList[2],3,probHash['6sub3'])\n",
    "# evalInstance.getStatsPerCard(6,3,probHash,ixList[0:10])\n",
    "# for n in range(2,card):\n",
    "#     stats = evalInstance.getStatsPerCard(card,n,probHash,ixList[0:10])\n",
    "#     print(stats)\n",
    "# evalInstance.statsForAllCardSubsets(10,probHash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-Seq data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/2023_03_01_v0_dataGathering/PoreC_Fibroblasts/adult_All_ONT_RNA_fromGEO.mat'\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "arrays = {}\n",
    "f = scipy.io.loadmat(filepath)\n",
    "for k, v in f.items():\n",
    "    arrays[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': array(b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Nov 24 09:59:45 2021',\n",
       "       dtype='|S76'),\n",
       " '__version__': array('1.0', dtype='<U3'),\n",
       " '__globals__': array([], dtype=float64),\n",
       " 'None': array([(b'All_ONT_RNA_20210719', b'MCOS', b'table', array([[3707764736],\n",
       "               [         2],\n",
       "               [         1],\n",
       "               [         1],\n",
       "               [         1],\n",
       "               [         1]], dtype=uint32))                             ],\n",
       "       dtype=[('s0', 'O'), ('s1', 'O'), ('s2', 'O'), ('arr', 'O')]),\n",
       " '__function_workspace__': array([[ 0,  1, 73, ...,  0,  0,  0]], dtype=uint8)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypergraph_poreC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
