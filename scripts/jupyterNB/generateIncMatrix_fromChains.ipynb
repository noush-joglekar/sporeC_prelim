{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hypernetx as hnx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import random\n",
    "#from PyComplexHeatmap import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/v0.analysis/scripts/pythonScripts/functions/')\n",
    "from incidenceToProjection import makeHiC_fromInc\n",
    "#from chains import makeIncDF_fromChainDists\n",
    "from chains import RealHiC\n",
    "from utils import flatten\n",
    "\n",
    "## Set up. \n",
    "dataDir = '/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/2023_03_01_v0_dataGathering/v0_hypergraphSimulations/getMultiwayInteractions_fromBPChains/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in example file\n",
    "exMat1 = np.loadtxt(f'{dataDir}chains_500_10000_1500_1696950861/chain_dist_281.txt')\n",
    "## Read in example file\n",
    "exMat2 = np.loadtxt(f'{dataDir}chains_500_10000_1500_1696950861/chain_dist_38.txt')\n",
    "\n",
    "nrow = exMat1.shape[0]\n",
    "cutoff = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chainDir = f'{dataDir}chains_500_10000_1500_1696950861/'\n",
    "num_files = 300\n",
    "binaryInit = RealHiC(chainDir,num_files)\n",
    "binMat = binaryInit.distMatToBinary(281)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(exMat1, cmap=\"YlGnBu\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(\"Distance matrix heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageNChains(seed,sampleSize,matching_files):\n",
    "    random.seed(seed)\n",
    "    mat = None\n",
    "    for f in random.sample(matching_files,sampleSize):\n",
    "        oneChain = np.loadtxt(f)\n",
    "        chainDFs.append(oneChain)\n",
    "        if mat is None:\n",
    "            mat = (oneChain / sampleSize)\n",
    "        else:\n",
    "            mat += (oneChain / sampleSize)\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distPattern = \"chain_dist_*.txt\"\n",
    "matching_files = glob.glob(f'{dataDir}chains_500_10000_1500_1681171613/{distPattern}')\n",
    "random.seed(10)\n",
    "sampleSize = 4\n",
    "\n",
    "avgMat = None\n",
    "dfs = []\n",
    "chainDFs = []\n",
    "\n",
    "for f in random.sample(matching_files,sampleSize):\n",
    "    oneChain = np.loadtxt(f)\n",
    "    chainDFs.append(oneChain)\n",
    "    if avgMat is None:\n",
    "        avgMat = (oneChain / sampleSize)\n",
    "    else:\n",
    "        avgMat += (oneChain / sampleSize)\n",
    "    chainDF = makeIncDF_fromChainDists(oneChain)\n",
    "    print(chainDF.shape)\n",
    "    dfs.append(chainDF)\n",
    "\n",
    "combined_incDF = pd.concat(dfs,axis=1)\n",
    "combined_incDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(avgMat, cmap=\"YlGnBu\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(\"Distance matrix heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    " \n",
    "for i, matrix in enumerate(chainDFs):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    im = plt.imshow(matrix, cmap=\"YlGnBu\")\n",
    "    plt.colorbar(im, fraction=0.05, pad=0.04)\n",
    "    plt.title(f\"Chain {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chainDFs[0][0:4,0:4])\n",
    "print(chainDFs[1][0:4,0:4])\n",
    "print(chainDFs[2][0:4,0:4])\n",
    "print(chainDFs[3][0:4,0:4])\n",
    "print(avgMat[0:4,0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneChain = makeIncDF_fromChainDists(avgMat)\n",
    "oneChain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "\n",
    "my_colors = [\"lightyellow\",'darkblue']\n",
    "my_cmap = ListedColormap(my_colors)\n",
    "bounds = [0, 0.5, 1]\n",
    "my_norm = BoundaryNorm(bounds, ncolors=len(my_colors))\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "im = sns.heatmap(combined_incDF, cmap=my_cmap,norm = my_norm)\n",
    "plt.title(\"Incidence DF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert incidence matrix to 2d hiC matrix\n",
    "def makeHiC_fromInc(incDF):\n",
    "    nrow = incDF.shape[0]\n",
    "    ncol = incDF.shape[1]\n",
    "    binIDs = list(incDF.index)\n",
    "    df = pd.DataFrame(np.zeros(shape = (nrow,nrow)), index=binIDs, columns=binIDs)\n",
    "    for read in incDF.columns:\n",
    "        arr = incDF[read][incDF[read] == 1].index\n",
    "        for a in arr:\n",
    "            df.loc[a][a] += 1\n",
    "        combs = list(combinations(arr,2))\n",
    "        for c in combs:\n",
    "            df.loc[c[0]][c[1]] += 1\n",
    "            df.loc[c[1]][c[0]] += 1\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_mat = makeHiC_fromInc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(hic_mat, cmap=\"YlOrRd\",norm = LogNorm(vmax=100, vmin = 0.05))\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(f\"Projection matrix: threshold = {cutoff}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain_dir = f'{dataDir}chains_500_10000_1500_1681171613/'\n",
    "chain_dir = f'{dataDir}chains_500_10000_1500_1696950861/'\n",
    "num_files = 1000\n",
    "hic_processor = RealHiC(chain_dir,num_files)\n",
    "hic1k = hic_processor.distFilesToRealHiC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(hic1k, cmap=\"YlOrRd\",norm = LogNorm())\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(f\"Real HiC matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(exMat1 < 500, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(card, bins='auto')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Cardinality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of cardinality from chain')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgMat1 = averageNChains(seed=101,sampleSize=5,matching_files = matching_files)\n",
    "chains1 = makeIncDF_fromChainDists(avgMat1)\n",
    "print(chains1.shape)\n",
    "\n",
    "avgMat2 = averageNChains(seed=102,sampleSize=5,matching_files = matching_files)\n",
    "chains2 = makeIncDF_fromChainDists(avgMat2)\n",
    "print(chains2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(avgMat1, cmap=\"YlGnBu\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(\"Avg Mat - 1\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "im = plt.imshow(avgMat2, cmap=\"YlGnBu\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04, label='balanced');\n",
    "plt.title(\"Avg Mat - 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains1_bin5 = increaseIncDF_binSize(chains1,5)\n",
    "chains2_bin5 = increaseIncDF_binSize(chains2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1 = hnx.Hypergraph.from_incidence_dataframe(chains1)\n",
    "H2 = hnx.Hypergraph.from_incidence_dataframe(chains2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_nodes = []\n",
    "for e in H1.edges:\n",
    "    h1_nodes.append(tuple(H1.edges[e]))\n",
    "\n",
    "h2_nodes = []\n",
    "for e in H2.edges:\n",
    "    h2_nodes.append(tuple(H2.edges[e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_elements = set(h1_nodes).intersection(set(h2_nodes))\n",
    "print(len(common_elements),len(h1_nodes),len(h2_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRATCHPAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains1 = makeIncDF_fromChainDists(exMat1,500)\n",
    "chains2 = makeIncDF_fromChainDists(exMat2,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains1by5 = increaseIncDF_binSize(chains1,5)\n",
    "chains1by5 = chains1by5.loc[:,chains1by5.sum() >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains2by5 = increaseIncDF_binSize(chains2,5)\n",
    "chains2by5 = chains2by5.loc[:,chains2by5.sum() >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increaseIncDF_binSize(df,binSize):\n",
    "    result = []\n",
    "    names = []\n",
    "    for i in range(0,len(df) - binSize,binSize):\n",
    "        summed_value = df.loc[i:i+binSize-1,:].sum()\n",
    "        summed_value[summed_value > 0] = 1\n",
    "        names.append(f\"Bin{i}:{i+binSize-1}\")\n",
    "        result.append(summed_value)\n",
    "    result_df = pd.DataFrame(result,index = names)\n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfToDict(df,result_dict):\n",
    "    for col in df.columns:\n",
    "        indices = df.index[df[col] == 1].tolist()\n",
    "        key = '_'.join(indices)\n",
    "\n",
    "        result_dict[key] = result_dict.get(key, 0) + 1\n",
    "    return(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToDF(hpDict):\n",
    "    indices = list(set(flatten([key.split('_') for key in hpDict.keys()])))\n",
    "    columns = []\n",
    "    colnames = []\n",
    "    counter = 0\n",
    "\n",
    "    for key, value in hpDict.items():\n",
    "        counter+=1\n",
    "        col_ix = key.split('_')\n",
    "        column = pd.Series([0] * len(indices),index = indices)  # Initialize row with zeros\n",
    "        column[col_ix] = 1\n",
    "        colName = f\"Read{counter}:{value}\"\n",
    "        colnames.append(colName)\n",
    "        columns.append(column)\n",
    "\n",
    "    df = pd.concat(columns,axis=1)\n",
    "    df.columns = colnames\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyDict = {}\n",
    "chains1_dict = dfToDict(chains1by5,emptyDict)\n",
    "emptyDict = {}\n",
    "chains2_dict = dfToDict(chains2by5,emptyDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains1_new = dictToDF(chains1_dict)\n",
    "chains1_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructFullDict(listOfDFs):\n",
    "    result_dict = {}\n",
    "    for df in listOfDFs:\n",
    "        result_dict = dfToDict(df,result_dict)\n",
    "    return(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF = dictToDF(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to make things more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append('/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/v0.analysis/scripts/pythonScripts/functions/')\n",
    "from incidenceToProjection import makeHiC_fromInc\n",
    "from chains import IncDFCreator, increaseIncDF_binSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/2023_03_01_v0_dataGathering/v0_hypergraphSimulations/getMultiwayInteractions_fromBPChains/'\n",
    "inputDir = 'chains_500_10000_1500_1681171613/'\n",
    "\n",
    "prim_cutoff = 500\n",
    "sec_cutoff = 550\n",
    "numProcesses = 4\n",
    "offDiagLim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNum = 5\n",
    "exMat = np.loadtxt(f'{dataDir}{inputDir}/chain_dist_{fileNum}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = IncDFCreator(numProcesses, prim_cutoff, sec_cutoff, offDiagLim)\n",
    "exChain = creator.makeIncDF_fromChainDists_mp(exMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNum = 7\n",
    "exMat = np.loadtxt(f'{dataDir}{inputDir}/chain_dist_{fileNum}.txt')\n",
    "exChain = creator.makeIncDF_fromChainDists_mp(exMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exChain.to_parquet(f'{dataDir}/tmp0.pq',compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "exChain.to_hdf(f'{dataDir}tmp.h5', key='df7', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exChain.to_pickle(f'{dataDir}/tmp0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_parquet(f'{dataDir}/tmp0.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = pd.read_pickle(f'{dataDir}/tmp0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = pd.read_hdf(f'{dataDir}tmp.h5',key='7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructFullDict(numFiles):\n",
    "    \"\"\"Takes in a directory of DFs and outputs a dict\"\"\"\n",
    "    result_dict = {}\n",
    "    numEdges = []\n",
    "    for ix in range(1,numFiles+1):\n",
    "        filePath = f'{dataDir}/{inputDir}/binConcatInc_{offDiagDist}_600_750_{ix}.pkl'\n",
    "        if os.path.isfile(filePath):\n",
    "            bIncDF = pd.read_pickle(filePath)\n",
    "            result_dict = dfToDict(bIncDF,result_dict)\n",
    "            nE = len(result_dict)\n",
    "            numEdges.append(nE)\n",
    "    return(result_dict,numEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import random\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('/gpfs/commons/groups/gursoy_lab/ajoglekar/Projects/2023_03_01_multiwayInteractions/v0.analysis/scripts/pythonScripts/functions/')\n",
    "from chains import dfToDict\n",
    "\n",
    "inputDir = 'chains_10k_500_projectionMtxOutput/'\n",
    "offDiagDist = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpEdges, numEdges = constructFullDict(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructFullDict_h5(numFiles):\n",
    "    \"\"\"Takes in a directory of DFs and outputs a dict\"\"\"\n",
    "    result_dict = {}\n",
    "    numEdges = []\n",
    "    for ix in range(1,numFiles+1):\n",
    "        filePath = f'{dataDir}/{inputDir}/binConcatInc_3_500_550.h5'\n",
    "        if os.path.isfile(filePath):\n",
    "            bIncDF = pd.read_hdf(filePath,key = f'df{ix}')\n",
    "            result_dict = dfToDict(bIncDF,result_dict)\n",
    "            nE = len(result_dict)\n",
    "            numEdges.append(nE)\n",
    "    return(result_dict,numEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypergraph_poreC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
